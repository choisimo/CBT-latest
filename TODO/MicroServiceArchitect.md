Kafka 기반 마이크로서비스 아키텍처 적용 검토 보고서
1. 검토 목적

본 보고서는 인증 서버(Auth-Server) 내 Diary 및 UserCustomSetting 관련 기능을 별도의 마이크로서비스로 분리하고, 서비스 간 통신에 Kafka를 도입하는 계획의 기술적 타당성, 구체성, 그리고 예상되는 주요 고려 사항을 종합적으로 평가하여 개선 방안을 제시하는 것을 목적으로 합니다.

2. 핵심 검토 결과 및 권고

전략적 적합성: Diary 및 UserCustomSetting 기능의 마이크로서비스 분리 및 Kafka 도입은 인증 서버의 핵심 책임(인증/인가) 집중, 시스템 전체의 관심사 분리(SoC), 확장성 및 유연성 향상 측면에서 전략적으로 매우 적합한 방향입니다.
계획의 구체성: 제시된 분리 계획은 신규 모듈 생성부터 도메인/DTO/로직 이전, Kafka Producer/Consumer 역할 정의, 테스트 및 문서화에 이르기까지 단계별로 구체적이고 체계적으로 구성되어 있습니다.
주요 도전 과제: 데이터 일관성 유지(특히 최종적 일관성), 서비스 간 API의 세밀한 설계, 분산 환경에서의 트랜잭션 관리, 그리고 운영 복잡성 증가에 대한 철저한 준비와 설계가 성공의 관건입니다.
권고 사항:
본 보고서에서 제시된 주요 기술적 고려 사항들을 반영하여 상세 설계를 보완합니다.
가장 핵심적인 이벤트 흐름(예: 사용자 생성/삭제에 따른 연관 데이터 처리)에 대해 PoC(Proof of Concept)를 진행하여 기술적 위험을 사전에 검증하고 경험을 축적합니다.
점진적인 마이그레이션 전략을 채택하고, 각 단계마다 충분한 테스트를 통해 안정성을 확보합니다.
3. 세부 검토 내용

3.1. 마이크로서비스 아키텍처 및 Kafka 도입의 적합성

인증 서버 내 Diary, UserCustomSetting 기능은 핵심 인증/인가 로직과 직접적인 관련성이 낮아, 현재 강한 결합은 인증 서버의 책임을 과도하게 만들고 복잡성을 증가시키고 있습니다.
기능 분리를 통해 각 마이크로서비스는 단일 책임 원칙(Single Responsibility Principle)을 더 잘 준수하게 되며, 독립적인 개발 주기, 배포 전략, 기술 스택 선택, 그리고 확장성을 가질 수 있게 됩니다.
Kafka를 활용한 비동기 이벤트 기반 통신은 서비스 간의 직접적인 의존성을 제거(느슨한 결합)하고, 특정 서비스의 장애가 다른 서비스로 전파되는 것을 완화하며(탄력성 증가), 이벤트 스트림을 통한 데이터 파이프라인 구축 등 다양한 아키텍처 패턴 적용의 기반이 됩니다.
3.2. 기능 분리 계획의 구체성 및 타당성

제시된 분리 계획은 신규 모듈 생성, 데이터베이스 스키마 분리, 도메인/DTO/서비스 로직의 체계적인 이동, 각 서비스에서의 Kafka Producer/Consumer 역할 명시, 그리고 테스트 및 문서화까지 포괄적으로 다루고 있어 실행 가능성이 높습니다.
각 서비스가 자체 데이터베이스 스키마를 관리하도록 하는 계획은 서비스 자율성을 극대화하고 데이터 모델 변경에 따른 영향을 해당 서비스 내로 국한시키는 좋은 전략입니다.
3.3. 현 프로젝트 구조와 분리 요구사항의 부합성

Diary.java 및 관련 DTO들, UserCustomSetting.java 엔티티는 현재 인증 서버의 com.authentication.auth.domain 및 dto.diary 패키지 내에 명확히 존재하며, User 엔티티와 @OneToMany 관계로 직접 연결되어 있어 분리 대상으로 식별하는 것은 타당합니다.
인증 서버가 인증 및 권한 부여라는 핵심 책임 외에 일기 관리, 사용자별 설정 관리 등 다양한 도메인 관심사를 처리하는 것은 애플리케이션의 복잡도를 높이고 향후 유지보수를 어렵게 만드는 요인이므로, 분리를 통해 이러한 구조적 문제를 개선할 수 있습니다.
4. 주요 기술적 고려 사항 및 심층 분석

4.1. 데이터 일관성 유지 전략 (Eventual Consistency)

목표: 비동기 통신 환경에서는 실시간 강한 일관성(Strong Consistency) 대신 **최종적 일관성(Eventual Consistency)**을 목표로 하며, 이를 위한 전략 수립이 필수적입니다.
이벤트 설계:
각 이벤트는 발생한 사실(Fact)을 명확히 나타내야 하며, 가능한 한 해당 이벤트 처리에 필요한 모든 데이터를 포함하여 다른 서비스의 추가적인 데이터 조회 요청을 최소화하는 것이 좋습니다 (Fat Event).
이벤트는 비즈니스 의미 단위로 원자적으로 발행되어야 합니다.
메시지 스키마 관리:
JSON 스키마 검증 또는 Apache Avro와 같은 스키마 레지스트리 시스템을 도입하여 메시지 포맷의 유효성을 보장하고, 스키마 변경 및 버전 관리를 체계적으로 수행해야 합니다.
멱등성(Idempotency) 보장:
Kafka 메시지는 네트워크 문제 등으로 인해 중복 전달될 수 있습니다. 컨슈머는 동일한 메시지를 여러 번 수신하여 처리하더라도 시스템 상태에 부작용이 없도록 멱등하게 설계되어야 합니다. (예: 메시지 내 고유 이벤트 ID를 사용하여 이미 처리된 이벤트인지 확인)
오류 처리 및 메시지 재처리:
컨슈머의 메시지 처리 실패 시, 즉각적인 재시도(Retry)와 지수 백오프(Exponential Backoff)를 적용한 순차적 재시도를 구현합니다.
최종적으로 처리에 실패한 메시지는 Dead Letter Queue (DLQ)로 보내 별도로 분석하고 수동 처리하거나, 보상 트랜잭션(Compensating Transaction)을 발동시키는 등의 정교한 오류 처리 메커니즘을 설계해야 합니다.
4.2. 마이크로서비스 간 API 설계 및 인증/인가 (필요시)

동기식 호출 최소화: Kafka를 주 통신 수단으로 사용하더라도, 경우에 따라 신규 서비스(diary-service, user-settings-service)가 인증 서버의 API를 호출하거나, 그 반대의 동기식 호출이 필요할 수 있습니다 (예: 데이터 검증, 실시간 정보 조회). 이러한 API는 RESTful 또는 gRPC 등으로 명확한 계약(엔드포인트, 요청/응답 DTO, 오류 코드)을 가지고 설계되어야 합니다.
서비스 간 인증/인가: 내부 서비스 간의 호출이라도 보안을 확보하기 위한 인증/인가 메커니즘(예: 상호 TLS (mTLS), OAuth2 Client Credentials Grant, API Key 등)을 적용해야 합니다. 인증 서버에서 발급된 사용자 토큰(JWT)을 내부 서비스로 전파하여 사용자 컨텍스트를 유지하고 권한을 검증하는 방안도 고려해야 합니다.
4.3. 분산 트랜잭션 관리

하나의 논리적 작업이 여러 마이크로서비스에 걸쳐 데이터를 변경해야 할 경우(예: 사용자 탈퇴 시 인증 정보 삭제 + 관련 설정 삭제 + 관련 일기 데이터 처리), 분산 트랜잭션 문제가 발생할 수 있습니다.
이를 해결하기 위해 Saga 패턴 도입을 적극적으로 검토해야 합니다. 각 서비스는 로컬 트랜잭션을 수행하고, 성공 또는 실패 이벤트를 Kafka로 발행하여 다음 단계를 진행하거나 보상 트랜잭션을 수행하도록 오케스트레이션 또는 코레오그래피 방식으로 구현합니다.
4.4. 운영 복잡성 증가 대비

통합 모니터링 및 로깅: 분산된 마이크로서비스 환경에서는 각 서비스의 상태, Kafka 토픽의 메시지 처리량, 지연 시간, 오류율 등을 중앙에서 통합적으로 모니터링하고 분석할 수 있는 시스템(예: Prometheus, Grafana, ELK Stack 또는 EFK Stack) 구축이 필수적입니다.
분산 추적 (Distributed Tracing): Jaeger, Zipkin 등의 도구를 활용하여 마이크로서비스 간의 요청 흐름을 추적하고 병목 지점이나 오류 원인을 쉽게 파악할 수 있도록 합니다.
CI/CD 파이프라인: 각 마이크로서비스는 독립적으로 빌드, 테스트, 배포될 수 있도록 CI/CD 파이프라인을 각각 구축하고 자동화해야 합니다.
장애 격리 및 회복성: 특정 서비스의 장애가 전체 시스템으로 확산되는 것을 방지하기 위해 서킷 브레이커(Circuit Breaker) 패턴, 격벽(Bulkhead) 패턴 등을 적용하고, 서비스 디스커버리(Service Discovery) 메커니즘을 통해 동적으로 서비스 인스턴스를 관리해야 합니다.
5. 결론 및 다음 단계 제안

Kafka를 이용한 마이크로서비스 분리 계획은 인증 서버의 책임을 명확히 하고 시스템 전체의 유연성, 확장성, 그리고 탄력성을 증대시키는 매우 전략적이고 올바른 방향입니다.

다만, 위에 제시된 데이터 일관성 전략, 서비스 간 API 및 인증/인가, 분산 트랜잭션 관리, 그리고 운영 환경의 복잡성 증가와 같은 기술적 과제들에 대한 깊이 있는 사전 설계와 철저한 준비가 병행되어야 성공적인 아키텍처 전환을 이룰 수 있습니다.

다음 단계 제안:

가장 핵심적인 이벤트 흐름 1~2개(예: 사용자 생성 및 관련 설정 기본값 생성, 사용자 삭제 및 관련 데이터 정리)를 선정하여 PoC(Proof of Concept)를 진행합니다. 이를 통해 Kafka 연동의 기술적 세부 사항을 검증하고, 발생 가능한 문제점을 사전에 파악하며, 팀 내 경험을 축적합니다.
PoC 진행 결과 및 본 보고서에서 제시된 고려 사항들을 바탕으로 각 서비스의 상세 설계 문서(메시지 스키마, API 명세, 오류 처리 방안 등 포함)를 구체적으로 보완합니다.
설계가 확정되면, 점진적으로 각 기능을 분리하여 마이그레이션을 진행하고, 각 단계마다 단위 테스트, 통합 테스트, E2E 테스트를 철저히 수행하여 시스템의 안정성을 확보합니다.
